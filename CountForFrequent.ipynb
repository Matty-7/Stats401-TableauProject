{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Weibo_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Threepoint shooter James made longdistance thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fee Note For the 76ers the NBA trade deadline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NBA McCollum made a sudden stop and hit a thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lakers 4for2 trade plan involved Westbrook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBA legend Vince Carter talked about the Nets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>NBADream1TeamThe best team for January 3 Mitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Hyde Sports Morning NewsFootball War Report Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>NBA Zero Distance Game Review Brunson made thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>happynewyear After the Warriors won their four...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>NBA Zero Distance Brunson threepointers in a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1939 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Cleaned_Weibo_Text\n",
       "0     Threepoint shooter James made longdistance thr...\n",
       "1     Fee Note For the 76ers the NBA trade deadline ...\n",
       "2     NBA McCollum made a sudden stop and hit a thre...\n",
       "3     The Lakers 4for2 trade plan involved Westbrook...\n",
       "4     NBA legend Vince Carter talked about the Nets ...\n",
       "...                                                 ...\n",
       "1934  NBADream1TeamThe best team for January 3 Mitch...\n",
       "1935  Hyde Sports Morning NewsFootball War Report Li...\n",
       "1936  NBA Zero Distance Game Review Brunson made thr...\n",
       "1937  happynewyear After the Warriors won their four...\n",
       "1938  NBA Zero Distance Brunson threepointers in a r...\n",
       "\n",
       "[1939 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading the new version of the CSV file to understand its structure\n",
    "try:\n",
    "    # Try reading a few rows to get an idea of the structure\n",
    "    preview_data_new = pd.read_csv('CleanedDataOfNBAShooters.csv')\n",
    "except pd.errors.ParserError as e:\n",
    "    # If there's a parsing error, display it\n",
    "    preview_data_new = f\"Error while reading the file: {str(e)}\"\n",
    "\n",
    "preview_data_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 3129),\n",
       " ('I', 2113),\n",
       " ('In', 1400),\n",
       " ('He', 1365),\n",
       " ('Lakers', 1005),\n",
       " ('Warriors', 842),\n",
       " ('Curry', 822),\n",
       " ('This', 700),\n",
       " ('James', 615),\n",
       " ('Heat', 595),\n",
       " ('If', 590),\n",
       " ('It', 548),\n",
       " ('After', 531),\n",
       " ('But', 519),\n",
       " ('Nuggets', 513),\n",
       " ('Weibo', 396),\n",
       " ('They', 370),\n",
       " ('No', 339),\n",
       " ('When', 324),\n",
       " ('Suns', 321)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Tokenizing the text and counting the occurrences of each word in the new dataset\n",
    "word_counter_new = Counter()\n",
    "for text in preview_data_new['Cleaned_Weibo_Text']:\n",
    "    words = text.split()\n",
    "    word_counter_new.update(words)\n",
    "\n",
    "# Filtering out only the capitalized words (potential proper nouns)\n",
    "capitalized_word_counter = {word: count for word, count in word_counter_new.items() if word.istitle()}\n",
    "\n",
    "# Finding the 20 most common capitalized words for a quick review\n",
    "most_common_capitalized_words = sorted(capitalized_word_counter.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "most_common_capitalized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Curry', 822),\n",
       " ('James', 615),\n",
       " ('Jordan', 312),\n",
       " ('Jokic', 311),\n",
       " ('Green', 271),\n",
       " ('Durant', 263),\n",
       " ('Harden', 249),\n",
       " ('Westbrook', 220),\n",
       " ('Kobe', 193),\n",
       " ('Irving', 189),\n",
       " ('Thompson', 173),\n",
       " ('Paul', 172),\n",
       " ('Murray', 167),\n",
       " ('Russell', 167),\n",
       " ('Allen', 155),\n",
       " ('Davis', 154),\n",
       " ('Butler', 150),\n",
       " ('Poole', 144),\n",
       " ('Ray', 141),\n",
       " ('Lillard', 137)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List of common English stop words\n",
    "stop_words = set([\n",
    "    'I', 'Me', 'My', 'Myself', 'We', 'Our', 'Ours', 'Ourselves', 'You', \"You're\", \"You've\", \"You'll\", \"You'd\", \n",
    "    'Your', 'Yours', 'Yourself', 'Yourselves', 'He', 'Him', 'His', 'Himself', 'She', \"She's\", 'Her', 'Hers', \n",
    "    'Herself', 'It', \"It's\", 'Its', 'Itself', 'They', 'Them', 'Their', 'Theirs', 'Themselves', 'What', 'Which', \n",
    "    'Who', 'Whom', 'This', 'That', \"That'll\", 'These', 'Those', 'Am', 'Is', 'Are', 'Was', 'Were', 'Be', 'Been', \n",
    "    'Being', 'Have', 'Has', 'Had', 'Having', 'Do', 'Does', 'Did', 'Doing', 'A', 'An', 'The', 'And', 'But', 'If', \n",
    "    'Or', 'Because', 'As', 'Until', 'While', 'Of', 'At', 'By', 'For', 'With', 'About', 'Against', 'Between', \n",
    "    'Into', 'Through', 'During', 'Before', 'After', 'Above', 'Below', 'To', 'From', 'Up', 'Down', 'In', 'Out', \n",
    "    'On', 'Off', 'Over', 'Under', 'Again', 'Further', 'Then', 'Once', 'Here', 'There', 'When', 'Where', 'Why', \n",
    "    'How', 'All', 'Any', 'Both', 'Each', 'Few', 'More', 'Most', 'Other', 'Some', 'Such', 'No', 'Nor', 'Not', \n",
    "    'Only', 'Own', 'Same', 'So', 'Than', 'Too', 'Very', 'S', 'T', 'Can', 'Will', 'Just', 'Don', \"Don't\", 'Should', \n",
    "    \"Should've\", 'Now', 'D', 'LL', 'M', 'O', 'Re', 'Ve', 'Y', 'Ain', 'Aren', \"Aren't\", 'Couldn', \"Couldn't\", \n",
    "    'Didn', \"Didn't\", 'Doesn', \"Doesn't\", 'Hadn', \"Hadn't\", 'Hasn', \"Hasn't\", 'Haven', \"Haven't\", 'Isn', \"Isn't\", \n",
    "    'Ma', 'Mightn', \"Mightn't\", 'Mustn', \"Mustn't\", 'Needn', \"Needn't\", 'Shan', \"Shan't\", 'Shouldn', \"Shouldn't\", \n",
    "    'Wasn', \"Wasn't\", 'Weren', \"Weren't\", 'Won', \"Won't\", 'Wouldn', \"Wouldn't\", 'NBA', 'Video', 'Weibo', 'Lakers', \n",
    "    'Warriors', 'Heat', 'Nuggets', 'Suns', 'Celtics', 'Rockets', 'Clippers', 'Bucks', 'Nets', 'Raptors', 'Thunder', \n",
    "    'Jazz', 'Although', 'Conference', 'Kings', 'Pacers', 'Pelicans', 'Pistons', 'Timberwolves', 'Trail', 'Blazers',\n",
    "    'League', 'Finals', 'Magic', 'Mavericks', 'Grizzlies', 'Hawks', 'Hornets', 'Bulls', 'Cavaliers', 'Knicks',\n",
    "    'Spurs', '76ers', 'Thunder', 'Wizards', 'Magic', 'Mavericks', 'Grizzlies', 'Hawks', 'Hornets', 'Bulls',\n",
    "    'Cavaliers', 'Knicks', 'However', 'Basketball', 'Cup', 'Heats', 'World', 'Western'\n",
    "    \n",
    "])\n",
    "\n",
    "# Filtering out the stop words\n",
    "filtered_word_counter = {word: count for word, count in capitalized_word_counter.items() if word not in stop_words}\n",
    "\n",
    "# Finding the 20 most common filtered words for a quick review\n",
    "most_common_filtered_words = sorted(filtered_word_counter.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "most_common_filtered_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
